{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cead284f-9398-4759-830a-15d0b8b70165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88222ca5-f82f-47fc-bf30-6c8d9d45a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR   = 'C:/Users/paula/Documents/Repositorio/MURA_prueba/' # directorio raíz\n",
    "study_type = 'XR_WRIST' # tipo de estudio\n",
    "\n",
    "DATA_CAT    = ['train', 'valid'] # división de datos\n",
    "study_label = {'positive': 1, 'negative': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c9c477-0553-42e6-8568-673af0474ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/paula/Documents/Repositorio/MURA_prueba/train/XR_WRIST/ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 665.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/paula/Documents/Repositorio/MURA_prueba/valid/XR_WRIST/ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 586.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# study_data es un diccionario con los datos de entrenamiento\n",
    "# y de validación obtenidos de la base de datos\n",
    "\n",
    "study_data = {}\n",
    "\n",
    "for phase in DATA_CAT:\n",
    "    BASE_DIR = ROOT_DIR + '%s/%s/' % (phase, study_type)\n",
    "    print(BASE_DIR, '\\n')\n",
    "    \n",
    "    #patients = list(os.walk(BASE_DIR))[0][1] # list of patient folder names\n",
    "    patients = os.listdir(BASE_DIR)\n",
    "    study_data[phase] = pd.DataFrame(columns=['Path', 'Count', 'Label'])\n",
    "    \n",
    "    i = 0\n",
    "    for patient in tqdm(patients): # recorremos carpetas de pacientes\n",
    "        for study in os.listdir(BASE_DIR + patient): # recorremos estudios en cada carpeta de paciente\n",
    "            label = study_label[study.split('_')[1]] # etiqueta 0 ó 1\n",
    "            path = BASE_DIR + patient + '/' + study + '/' # ruta del estudio\n",
    "            study_data[phase].loc[i] = [path, len(os.listdir(path)), label] # añadimos fila\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ea9006-8be8-4f58-aa63-cc26ad783371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Count</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/paula/Documents/Repositorio/MURA_prue...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/paula/Documents/Repositorio/MURA_prue...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/paula/Documents/Repositorio/MURA_prue...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/paula/Documents/Repositorio/MURA_prue...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  Count  Label\n",
       "0  C:/Users/paula/Documents/Repositorio/MURA_prue...      3      1\n",
       "1  C:/Users/paula/Documents/Repositorio/MURA_prue...      4      0\n",
       "2  C:/Users/paula/Documents/Repositorio/MURA_prue...      3      1\n",
       "3  C:/Users/paula/Documents/Repositorio/MURA_prue...      3      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_data['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cc6fda-e57f-40d2-8151-1fe12093aa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Count</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/paula/Documents/Repositorio/MURA_prue...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/paula/Documents/Repositorio/MURA_prue...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/paula/Documents/Repositorio/MURA_prue...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/paula/Documents/Repositorio/MURA_prue...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/paula/Documents/Repositorio/MURA_prue...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  Count  Label\n",
       "0  C:/Users/paula/Documents/Repositorio/MURA_prue...      4      1\n",
       "1  C:/Users/paula/Documents/Repositorio/MURA_prue...      2      1\n",
       "2  C:/Users/paula/Documents/Repositorio/MURA_prue...      3      1\n",
       "3  C:/Users/paula/Documents/Repositorio/MURA_prue...      3      1\n",
       "4  C:/Users/paula/Documents/Repositorio/MURA_prue...      1      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_data['valid'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f92ba164-e5ec-41cc-b622-c37855913bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "######## CREAMOS DATA LOADER Y CLASE DATASET ASOCIADA\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c629ec1-518d-41f7-9744-575198a56970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import copy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab979998-3c39-42db-b500-c3c354409ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "C:/Users/paula/Documents/Repositorio/MURA_prueba/valid/XR_WRIST/patient11187/study1_positive/\n"
     ]
    }
   ],
   "source": [
    "print (label)\n",
    "print (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eeb5888-166f-4765-8d7f-f97c1faa863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        ]),\n",
    "    'valid': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3b6163-7e39-42aa-a35d-c687e63530cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths  # Asegúrate de que file_paths sea una lista\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.file_paths[index])  # Convertir a str antes de abrir la imagen\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c649fce-e936-41ff-a5f0-4ec6c2c21e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_paths = study_data['train']['Path'].tolist()\n",
    "train_labels = study_data['train']['Label'].tolist()\n",
    "\n",
    "valid_file_paths = study_data['valid']['Path'].tolist()\n",
    "valid_labels = study_data['valid']['Label'].tolist()\n",
    "\n",
    "train_dataset = ImageDataset(file_paths=train_file_paths, labels=train_labels, transform=transform['train'])\n",
    "valid_dataset = ImageDataset(file_paths=valid_file_paths, labels=valid_labels, transform=transform['valid'])\n",
    "\n",
    "#train_dataset = ImageDataset(file_paths =image_path, labels=label, transform=transform['train'])\n",
    "#valid_dataset = ImageDataset(file_paths =image_path, labels=label, transform=transform['valid'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f72a086-be88-43a9-b9b6-cb0b6b811b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_batches = len(train_dataloader)\n",
    "valid_num_batches = len(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "601038b4-da59-40d3-9544-bb43ac651697",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(study_data[x]) for x in DATA_CAT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be7c3399-d46d-4646-a5ce-2cf0583efce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 4, 'valid': 5}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4309e78b-4916-461a-80bd-3df03285d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31bbd804-3648-45ff-831d-94f35d8d243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(df, cat):\n",
    "    '''\n",
    "    Returns number of images in a study type dataframe which are of abnormal or normal\n",
    "    Args:\n",
    "    df -- dataframe\n",
    "    cat -- category, \"positive\" for abnormal and \"negative\" for normal\n",
    "    '''\n",
    "    return df[df['Path'].str.contains(cat)]['Count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b170bf8-6e24-46d2-bc4d-5ddfc4f2f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tai = total abnormal images, tni = total normal images\n",
    "tai = {x: get_count(study_data[x], 'positive') for x in DATA_CAT}\n",
    "tni = {x: get_count(study_data[x], 'negative') for x in DATA_CAT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "979b87cd-492b-4e2a-a7d2-c6687a9a4442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tai: {'train': 9, 'valid': 13}\n",
      "tni: {'train': 4, 'valid': 0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('tai:', tai)\n",
    "print('tni:', tni, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d4cbaa-f75a-4f85-83e5-b12bbf685e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52a03a2d-a791-4740-bf71-a3cdc2adb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_p(x):\n",
    "    '''convert numpy float to Variable tensor float'''    \n",
    "    return Variable(torch.FloatTensor([x]), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2076f490-48ec-49e7-976f-9390cbb8ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wt1 = {x: n_p(tni[x] / (tni[x] + tai[x])) for x in DATA_CAT}\n",
    "Wt0 = {x: n_p(tai[x] / (tni[x] + tai[x])) for x in DATA_CAT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e842ece-2ffe-4b99-9500-82e50e7fecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wt0 train: tensor([0.6923])\n",
      "Wt0 valid: tensor([1.])\n",
      "Wt1 train: tensor([0.3077])\n",
      "Wt1 valid: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print('Wt0 train:', Wt0['train'])\n",
    "print('Wt0 valid:', Wt0['valid'])\n",
    "print('Wt1 train:', Wt1['train'])\n",
    "print('Wt1 valid:', Wt1['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe5ae53a-e4d3-4008-8a79-58b2f01d7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "############### ENTRENAMIENTO DEL MODELO\n",
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a5464ac-2015-4f19-ad6e-c11173d23ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de pérdida \n",
    "class Loss(torch.nn.modules.Module):\n",
    "    def __init__(self, Wt1, Wt0):\n",
    "        super(Loss, self).__init__()\n",
    "        self.Wt1 = Wt1\n",
    "        self.Wt0 = Wt0\n",
    "        \n",
    "    def forward(self, inputs, targets, phase):\n",
    "        loss = - (self.Wt1[phase] * targets * inputs.log() + self.Wt0[phase] * (1 - targets) * (1 - inputs).log())\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05118ff2-cd49-4eb3-8152-71a4f7440a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from densenet import densenet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8097f492-f692-49ad-82be-014505bcfa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\Documents\\Repositorio\\Test\\densenet.py:115: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "model = densenet169(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89ad9128-5798-4d2b-8504-2102e1eb844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\miniforge3\\envs\\tfg\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "criterion = Loss(Wt1, Wt0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7466da76-7440-489b-8cc0-5bd12de912af",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "195eb2a1-44e1-4061-b420-79b13912b89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1\n",
      "Valid batches: 1\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "costs = {x:[] for x in DATA_CAT} # for storing costs per epoch\n",
    "accs = {x:[] for x in DATA_CAT} # for storing accuracies per epoch\n",
    "print('Train batches:',  train_num_batches)\n",
    "print('Valid batches:', valid_num_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c55960d-6f7d-4a66-9adb-d7122d2f8673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/paula/Documents/Repositorio/MURA_prueba/train/XR_WRIST/patient00021/study1_positive/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# get the inputs\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\tfg\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\tfg\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\tfg\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m----> 8\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convertir a str antes de abrir la imagen\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index]\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\tfg\\Lib\\site-packages\\PIL\\Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/paula/Documents/Repositorio/MURA_prueba/train/XR_WRIST/patient00021/study1_positive/'"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    #confusion_matrix = {x: meter.ConfusionMeter(2, normalized=True) \n",
    "    #                    for x in DATA_CAT}\n",
    "        \n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in DATA_CAT:\n",
    "        model.train(phase=='train')\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "           \n",
    "        # Iterate over data.\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            # get the inputs\n",
    "            print(i, end='\\r')\n",
    "            inputs = data['images'][0]\n",
    "            labels = data['label'].type(torch.FloatTensor)\n",
    "            # wrap them in Variable\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.mean(outputs)\n",
    "            loss = criterion(outputs, labels, phase)\n",
    "            running_loss += loss.data[0]\n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # statistics\n",
    "            preds = (outputs.data > 0.5).type(torch.FloatTensor)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            #confusion_matrix[phase].add(preds, labels.data)\n",
    "            \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "        costs[phase].append(epoch_loss)\n",
    "        accs[phase].append(epoch_acc)\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            #print('Confusion Meter:\\n', confusion_matrix[phase].value())\n",
    "            \n",
    "        # deep copy the model\n",
    "        if phase == 'valid':\n",
    "            scheduler.step(epoch_loss)\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Time elapsed: {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41507148-fcdd-4129-8ac7-28af8e4b97ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec2992-3c7f-4fbe-a8d2-29fb92c121cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
