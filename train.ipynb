{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18bbedb0-464f-44e5-9d26-a9fadc2049cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m meter\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_training\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchnet'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "from torchnet import meter\n",
    "from torch.autograd import Variable\n",
    "from utils import plot_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316937e9-643a-4e04-aef5-b676c69bb5fc",
   "metadata": {},
   "source": [
    "Este código define una lista llamada data_cat que contiene dos categorías de datos: \"train\" y \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b91fba-f9a7-44f0-ad2f-e66081fdaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = ['train', 'valid'] # data categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82738ff-4a21-42e4-9d2b-0f0192283858",
   "metadata": {},
   "source": [
    "Este código define una función train_model que entrena un modelo de aprendizaje automático, esta función entrena un modelo de PyTorch utilizando un bucle de entrenamiento y validación, calculando la pérdida y precisión en cada época, y guardando el mejor modelo obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6fde06e-dd06-4f1b-8bcd-44ee20a9a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, scheduler, \n",
    "                dataset_sizes, num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    costs = {x:[] for x in data_cat} # for storing costs per epoch\n",
    "    accs = {x:[] for x in data_cat} # for storing accuracies per epoch\n",
    "    print('Train batches:', len(dataloaders['train']))\n",
    "    print('Valid batches:', len(dataloaders['valid']), '\\n')\n",
    "    for epoch in range(num_epochs):\n",
    "        confusion_matrix = {x: meter.ConfusionMeter(2, normalized=True) \n",
    "                            for x in data_cat}\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in data_cat:\n",
    "            model.train(phase=='train')\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                # get the inputs\n",
    "                print(i, end='\\r')\n",
    "                inputs = data['images'][0]\n",
    "                labels = data['label'].type(torch.FloatTensor)\n",
    "                # wrap them in Variable\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                outputs = torch.mean(outputs)\n",
    "                loss = criterion(outputs, labels, phase)\n",
    "                running_loss += loss.data[0]\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # statistics\n",
    "                preds = (outputs.data > 0.5).type(torch.cuda.FloatTensor)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                confusion_matrix[phase].add(preds, labels.data)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            costs[phase].append(epoch_loss)\n",
    "            accs[phase].append(epoch_acc)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            print('Confusion Meter:\\n', confusion_matrix[phase].value())\n",
    "            # deep copy the model\n",
    "            if phase == 'valid':\n",
    "                scheduler.step(epoch_loss)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Time elapsed: {:.0f}m {:.0f}s'.format(\n",
    "                time_elapsed // 60, time_elapsed % 60))\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: {:4f}'.format(best_acc))\n",
    "    plot_training(costs, accs)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa725455-b563-4a93-a238-cfa325ab3f0c",
   "metadata": {},
   "source": [
    "Esta función get_metrics calcula las métricas de evaluación de un modelo en un conjunto de datos específico, ya sea de entrenamiento o validación. Calcula la pérdida, la precisión y la matriz de confusión de un modelo en un conjunto de datos específico y las imprime para su evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b45195a-cec9-4f8d-901b-ddebc051cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model, criterion, dataloaders, dataset_sizes, phase='valid'):\n",
    "    '''\n",
    "    Loops over phase (train or valid) set to determine acc, loss and \n",
    "    confusion meter of the model.\n",
    "    '''\n",
    "    confusion_matrix = meter.ConfusionMeter(2, normalized=True)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for i, data in enumerate(dataloaders[phase]):\n",
    "        print(i, end='\\r')\n",
    "        labels = data['label'].type(torch.FloatTensor)\n",
    "        inputs = data['images'][0]\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.mean(outputs)\n",
    "        loss = criterion(outputs, labels, phase)\n",
    "        # statistics\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        preds = (outputs.data > 0.5).type(torch.cuda.FloatTensor)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        confusion_matrix.add(preds, labels.data)\n",
    "\n",
    "    loss = running_loss / dataset_sizes[phase]\n",
    "    acc = running_corrects / dataset_sizes[phase]\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, loss, acc))\n",
    "    print('Confusion Meter:\\n', confusion_matrix.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca72b99-3cb6-408b-bb3a-396be2af13d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
